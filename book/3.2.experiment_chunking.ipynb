{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. Chunking Experiment\n",
    "\n",
    "There are multiple methods of ingestion, depending on the type of data. For example, unstructured data such as documents or web pages can be split into chunks and embedded into vectors, while structured data such as tables or databases can be summarized or converted into natural language. In our case, since we are working with text data, we will look into different chunking strategies.\n",
    "\n",
    "<!--\n",
    "The search solution is comprised of both **ingestion** and **retrieval**. One does not exist without the other. While other experiments are focused on data retrieval, ingestion plays equal importance in the effectiveness of the search solution. During this experiment, we will look at various chunking strategies. -->\n",
    "\n",
    "## Experiment Overview\n",
    "\n",
    "<!-- Certain aspects of data ingestion need to be experimented as part of the experimentation phase: -->\n",
    "\n",
    "<!-- # Chunking Strategy\n",
    "\n",
    "Code also https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/customskills/utils/chunker/text_chunker.py\n",
    "\n",
    "There are multiple methods of ingestion, depending on the type of data. For example, unstructured data such as documents or web pages can be split into chunks and embedded into vectors, while structured data such as tables or databases can be summarized or converted into natural language. In our case, since we are working with unstructured text data, we will look into different chunking strategies.\n",
    " -->\n",
    "\n",
    "| **Topic**                 | Description                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
    "| ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| üìù **Hypothesis**         | Exploratory hypothesis: \"Can introducing a new chunking strategy improve system's performance?\"                                                                                                                                                                                                                                                                                                                                                |\n",
    "| ‚öñÔ∏è **Comparison**         | We will compare [MarkdownHeaderTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/markdown_header_metadata), [MarkdownTextSplitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/markdown_header_metadata) and semantic chunking strategy ([SemanticChunker](https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker)). |\n",
    "| üéØ **Evaluation Metrics** | We will look at Accuracy and Cosine Similarity to compare the performance.                                                                                                                                                                                                                                                                                                                                                                     |\n",
    "| üìä **Data**               | The data that we will use consists of [code-with-engineering](../data/docs/code-with-engineering/) and [code-with-mlops](../data/docs/code-with-mlops/) sections from Solution Ops repository.                                                                                                                                                                                                                                                 |\n",
    "| üìä **Evaluation Dataset** | [300 question-answer](./output/qa/evaluation/qa_pairs_solutionops.json) pairs generated from [code-with-engineering](../data/docs/code-with-engineering/) and [code-with-mlops](../data/docs/code-with-mlops/) sections from Solution Ops repository. See [Generation QA Notebook](./5.1.generation-qa.ipynb) for insights on how they were generated.                                                                                         |\n",
    "\n",
    "```{note}\n",
    "Our goal here is not to identify which chunking strategy is the ‚Äúbest‚Äù in general but rather to demonstrate how the choice of chunking may have a non-trivial impact on the ultimate outcome from the RAG solution.\n",
    "```\n",
    "\n",
    "<!-- üìù**Hypothesis**\n",
    "\n",
    "Exploratory hypothesis: \"Can introducing a new chunking strategy improve system's performance?\"\n",
    "\n",
    "üéØ **Evaluation Metrics**\n",
    "\n",
    "For this experiment we will look at Accuracy and Cosine Similarity to compare the performance.\n",
    "\n",
    "üìä **Data**\n",
    "\n",
    "In this experiment, the data that we would like to chunk consists of the first 200 documents from the Solution Ops Playbook. -->\n",
    "\n",
    "<!-- The metrics used for document retrieval evaluation. -->\n",
    "\n",
    "<!-- [Learnings fromm other engagements](https://github.com/microsoft/rag-openai/blob/main/topics/RAG_EnablingSearch.md#learnings-from-engagements-1) -->\n",
    "\n",
    "<!-- https://vectara.com/blog/grounded-generation-done-right-chunking/#:~:text=In%20the%20context%20of%20Grounded%20Generation%2C%20chunking%20is,find%20natural%20segments%20like%20complete%20sentences%20or%20paragraphs. -->\n",
    "\n",
    "<!-- https://towardsdatascience.com/how-to-chunk-text-data-a-comparative-analysis-3858c4a0997a -->\n",
    "\n",
    "<!-- https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5\n",
    "\n",
    "Example code: https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/code/data-chunking/textsplit-data-chunking-example.ipynb\n",
    "\n",
    "Read [Common Chunking Technique](https://learn.microsoft.com/en-us/azure/search/semantic-search-overview), [Content overlap considerations](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents#content-overlap-considerations), [Simple example of how to create chunks with sentences](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-chunk-documents#content-overlap-considerations)\n",
    "\n",
    "CODE: https://github.com/microsoft/rag-openai/blob/438999a5470bef7946fa1c8714ed1090e1ed40c3/samples/searchEvaluation/customskills/utils/chunker/text_chunker.py -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why does chunking matter?\n",
    "\n",
    "When processing data, splitting the source documents into chunks requires care and expertise to ensure the resulting chunks are small enough to be effective during fact retrieval but not too small so that enough context is provided during summarization.\n",
    "\n",
    "_Why do we even need to chunk?_ you may ask.\n",
    "\n",
    "The models used to generate embedding vectors have maximum limits on the text fragments provided as input. For example, the maximum length of input text for the Azure OpenAI embedding models is **8,191** tokens. Given that each token is around 4 characters of text for common OpenAI models, this maximum limit is equivalent to around 6000 words of text. If you're using these models to generate embeddings, it's critical that the input text stays under the limit. Partitioning your content into chunks ensures that your data can be processed by the model used for indexing and queries.\n",
    "\n",
    "In our workshop, we work with text documents. Refer to [Types of Tet Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/#types-of-text-splitters) for an overview of supported options from LangChain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./pre-requisites.ipynb\n",
    "\n",
    "import glob\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the documents from Solution Ops Playbook (from `code-with-engineering` and `code-with-mlops` folders):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_from_folder(paths) -> list[str]:\n",
    "    markdown_documents = []\n",
    "    for path in paths:\n",
    "        for file in glob.glob(path, recursive=True):\n",
    "            loader = UnstructuredFileLoader(file)\n",
    "            document = loader.load()\n",
    "            markdown_documents.append(document)\n",
    "    return markdown_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "import ntpath\n",
    "paths = [\"../data/docs/code-with-engineering/**/*.md\",\"../data/docs/code-with-mlops/**/*.md\"]\n",
    "\n",
    "if os.name == \"nt\":\n",
    "    paths = [ntpath.normpath(path) for path in paths]\n",
    "documents = load_documents_from_folder(\n",
    "    paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Markdown Header Text Splitter\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this approach we will leverage the fact that our documents are markdown files and we will consider that the markdown pages are well structured. Therefore, we will split using the markdown headers.\n",
    "\n",
    "### Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load LangChain's `MarkdownHeaderTextSplitter` to split the text for us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we want to split this markdown:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"# Foo\\n\\n ## Bar\\n\\nHi this is Jim  \\nHi this is Joe\\n\\n ## Baz\\n\\n Hi this is Molly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the headers to split on:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Hi this is Jim\\nHi this is Joe', metadata={'Header 1': 'Foo', 'Header 2': 'Bar'}),\n",
       " Document(page_content='Hi this is Molly', metadata={'Header 1': 'Foo', 'Header 2': 'Baz'})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks_md_headers(documents: list) -> list:\n",
    "    print(\"Creating chunks...\")\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "\n",
    "    chunk_id = 0\n",
    "\n",
    "    chunks = {\n",
    "        \"chunkId\": [],\n",
    "        \"chunkContent\": [],\n",
    "        \"source\": []\n",
    "    }\n",
    "\n",
    "    for document in documents:\n",
    "        current_chunks_text_list = markdown_splitter.split_text(\n",
    "            document[0].page_content)\n",
    "\n",
    "        for i, chunk in enumerate(current_chunks_text_list):\n",
    "            chunks['chunkId'].append(f\"chunk{chunk_id}_{i}\")\n",
    "            chunks['chunkContent'].append(chunk.page_content)\n",
    "            chunks['source'].append(document[0].metadata['source'])\n",
    "\n",
    "        chunk_id += 1\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating chunks...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunkId</th>\n",
       "      <th>chunkContent</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chunk0_0</td>\n",
       "      <td>Structure of a Sprint  \\nThe purpose of this d...</td>\n",
       "      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chunk1_0</td>\n",
       "      <td>Who We Are  \\nOur team, ISE (Industry Solution...</td>\n",
       "      <td>../data/docs/code-with-engineering/ISE.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chunk2_0</td>\n",
       "      <td>Engineering Fundamentals Checklist  \\nThis che...</td>\n",
       "      <td>../data/docs/code-with-engineering/ENG-FUNDAME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chunk3_0</td>\n",
       "      <td>ISE Code-With Engineering Playbook  \\nAn engin...</td>\n",
       "      <td>../data/docs/code-with-engineering/index.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chunk4_0</td>\n",
       "      <td>Work Item ID  \\nFor more information about how...</td>\n",
       "      <td>../data/docs/code-with-engineering/code-review...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunkId                                       chunkContent  \\\n",
       "0  chunk0_0  Structure of a Sprint  \\nThe purpose of this d...   \n",
       "1  chunk1_0  Who We Are  \\nOur team, ISE (Industry Solution...   \n",
       "2  chunk2_0  Engineering Fundamentals Checklist  \\nThis che...   \n",
       "3  chunk3_0  ISE Code-With Engineering Playbook  \\nAn engin...   \n",
       "4  chunk4_0  Work Item ID  \\nFor more information about how...   \n",
       "\n",
       "                                              source  \n",
       "0  ../data/docs/code-with-engineering/SPRINT-STRU...  \n",
       "1          ../data/docs/code-with-engineering/ISE.md  \n",
       "2  ../data/docs/code-with-engineering/ENG-FUNDAME...  \n",
       "3        ../data/docs/code-with-engineering/index.md  \n",
       "4  ../data/docs/code-with-engineering/code-review...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_with_md_headers = create_chunks_md_headers(\n",
    "    documents)\n",
    "\n",
    "df_chunks_with_md_headers = pd.DataFrame(chunks_with_md_headers)\n",
    "df_chunks_with_md_headers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of lengths in the chunks.\n",
    "\n",
    "We create a new colum called chunk_text_length which contains the length of the chunk_text column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunkId</th>\n",
       "      <th>chunkContent</th>\n",
       "      <th>source</th>\n",
       "      <th>chunk_text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chunk0_0</td>\n",
       "      <td>Structure of a Sprint  \\nThe purpose of this d...</td>\n",
       "      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chunk1_0</td>\n",
       "      <td>Who We Are  \\nOur team, ISE (Industry Solution...</td>\n",
       "      <td>../data/docs/code-with-engineering/ISE.md</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chunk2_0</td>\n",
       "      <td>Engineering Fundamentals Checklist  \\nThis che...</td>\n",
       "      <td>../data/docs/code-with-engineering/ENG-FUNDAME...</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chunk3_0</td>\n",
       "      <td>ISE Code-With Engineering Playbook  \\nAn engin...</td>\n",
       "      <td>../data/docs/code-with-engineering/index.md</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chunk4_0</td>\n",
       "      <td>Work Item ID  \\nFor more information about how...</td>\n",
       "      <td>../data/docs/code-with-engineering/code-review...</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chunk5_0</td>\n",
       "      <td>FAQ  \\nThis is a list of questions / frequentl...</td>\n",
       "      <td>../data/docs/code-with-engineering/code-review...</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chunk6_0</td>\n",
       "      <td>Code Reviews  \\nDevelopers working on projects...</td>\n",
       "      <td>../data/docs/code-with-engineering/code-review...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chunk7_0</td>\n",
       "      <td>Inclusion in Code Review  \\nBelow are some poi...</td>\n",
       "      <td>../data/docs/code-with-engineering/code-review...</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chunk8_0</td>\n",
       "      <td>Pull Requests  \\nChanges to any main codebase ...</td>\n",
       "      <td>../data/docs/code-with-engineering/code-review...</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chunk9_0</td>\n",
       "      <td>Code Review Tools  \\nCustomize ADO  \\nTask boa...</td>\n",
       "      <td>../data/docs/code-with-engineering/code-review...</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunkId                                       chunkContent  \\\n",
       "0  chunk0_0  Structure of a Sprint  \\nThe purpose of this d...   \n",
       "1  chunk1_0  Who We Are  \\nOur team, ISE (Industry Solution...   \n",
       "2  chunk2_0  Engineering Fundamentals Checklist  \\nThis che...   \n",
       "3  chunk3_0  ISE Code-With Engineering Playbook  \\nAn engin...   \n",
       "4  chunk4_0  Work Item ID  \\nFor more information about how...   \n",
       "5  chunk5_0  FAQ  \\nThis is a list of questions / frequentl...   \n",
       "6  chunk6_0  Code Reviews  \\nDevelopers working on projects...   \n",
       "7  chunk7_0  Inclusion in Code Review  \\nBelow are some poi...   \n",
       "8  chunk8_0  Pull Requests  \\nChanges to any main codebase ...   \n",
       "9  chunk9_0  Code Review Tools  \\nCustomize ADO  \\nTask boa...   \n",
       "\n",
       "                                              source  chunk_text_length  \n",
       "0  ../data/docs/code-with-engineering/SPRINT-STRU...                468  \n",
       "1          ../data/docs/code-with-engineering/ISE.md                263  \n",
       "2  ../data/docs/code-with-engineering/ENG-FUNDAME...                793  \n",
       "3        ../data/docs/code-with-engineering/index.md                357  \n",
       "4  ../data/docs/code-with-engineering/code-review...                325  \n",
       "5  ../data/docs/code-with-engineering/code-review...                548  \n",
       "6  ../data/docs/code-with-engineering/code-review...                111  \n",
       "7  ../data/docs/code-with-engineering/code-review...                852  \n",
       "8  ../data/docs/code-with-engineering/code-review...                653  \n",
       "9  ../data/docs/code-with-engineering/code-review...                392  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks_with_md_headers['chunk_text_length'] = df_chunks_with_md_headers['chunkContent'].apply(\n",
    "    lambda x: len(x.split()))\n",
    "df_chunks_with_md_headers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the distribution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.histogram(df_chunks_with_md_headers, x='chunk_text_length',\n",
    "#                    title='Histogram of Chunk Text Length', nbins=80, marginal='box')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./images/md_header_text_splitter_histogram.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "In the interest of time, we have already chunked the data from Solution Ops repo using Markdown Header Text Splitter approach. The result can be found at [md-header-text-splitter-engineering-mlops.json](./output/pre-generated/chunking/md-header-text-splitter-engineering-mlops.json)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Markdown Text Splitter using tiktoken encoder\n",
    "\n",
    "### Overview\n",
    "\n",
    "To decide the length of each chunk, we will look at the distribution of the document lengths and the distribution of the chunk lengths. We will then decide on a chunk length that will give us a good distribution of chunk lengths. We will use a splitter that uses the tiktoken tokenizer to split the documents into chunks. Hence we do the following:\n",
    "\n",
    "1. Tokenize all the documents, and look at the distribution of the document lengths\n",
    "1. Based on the above distribution, decide on a chunk length\n",
    "1. Split the documents into chunks of the decided length using MarkdownTextSplitter.from_tiktoken_encoder()\n",
    "\n",
    "### Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load LangChain's `MarkdownTextSplitter` to split the text for us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split a text via `split_text` function. Let's take a sample text:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is the text I would like to chunk up. It is the example text for this exercise\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up the text splitted. You need to specify the `chunk overlap` and `chunk size`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5\n",
    "chunk_overlap = 3\n",
    "markdown_splitter = MarkdownTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is the text I would like to chunk up. It is the example text for this exercise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the text I',\n",
       " 'the text I would like',\n",
       " 'I would like to chunk',\n",
       " 'like to chunk up.',\n",
       " 'chunk up. It is',\n",
       " 'It is the example text',\n",
       " 'the example text for this',\n",
       " 'text for this exercise']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_chunks_text_list = markdown_splitter.split_text(text)\n",
    "current_chunks_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ntpath\n",
    "def load_md_documents_from_folder(path: str) -> list[str]:\n",
    "    print(\"Loading documents...\")\n",
    "    data_documents = {\n",
    "        \"solutionops_section\": [],\n",
    "        \"document_object\": [],\n",
    "        \"document_text\": [],\n",
    "        \"document_length\": [],\n",
    "        \"document_path\": []\n",
    "    }\n",
    "\n",
    "    for path in paths:\n",
    "        for file in glob.glob(path, recursive=True):\n",
    "            loader = UnstructuredFileLoader(file)\n",
    "            document = loader.load()\n",
    "            data_documents[\"solutionops_section\"].append(ntpath.normpath(file).split(\"\\\\\")[3])\n",
    "            data_documents[\"document_object\"].append(document)\n",
    "            data_documents[\"document_text\"].append(document[0].page_content)\n",
    "            data_documents[\"document_length\"].append(\n",
    "                len(document[0].page_content.split()))\n",
    "            data_documents[\"document_path\"].append(file)\n",
    "\n",
    "        # markdown_documents.append(document)\n",
    "    return data_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "paths = [\"../data/docs/code-with-engineering/**/*.md\",\"../data/docs/code-with-mlops/**/*.md\"]\n",
    "\n",
    "if os.name == \"nt\":\n",
    "    paths = [ntpath.normpath(path) for path in paths]\n",
    "markdown_documents = load_md_documents_from_folder(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solutionops_section</th>\n",
       "      <th>document_object</th>\n",
       "      <th>document_text</th>\n",
       "      <th>document_length</th>\n",
       "      <th>document_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>code-with-engineering</td>\n",
       "      <td>[page_content='Structure of a Sprint\\n\\nThe pu...</td>\n",
       "      <td>Structure of a Sprint\\n\\nThe purpose of this d...</td>\n",
       "      <td>468</td>\n",
       "      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>code-with-engineering</td>\n",
       "      <td>[page_content='Who We Are\\n\\nOur team, ISE (In...</td>\n",
       "      <td>Who We Are\\n\\nOur team, ISE (Industry Solution...</td>\n",
       "      <td>263</td>\n",
       "      <td>../data/docs/code-with-engineering/ISE.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>code-with-engineering</td>\n",
       "      <td>[page_content=\"Engineering Fundamentals Checkl...</td>\n",
       "      <td>Engineering Fundamentals Checklist\\n\\nThis che...</td>\n",
       "      <td>793</td>\n",
       "      <td>../data/docs/code-with-engineering/ENG-FUNDAME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>code-with-engineering</td>\n",
       "      <td>[page_content='ISE Code-With Engineering Playb...</td>\n",
       "      <td>ISE Code-With Engineering Playbook\\n\\nAn engin...</td>\n",
       "      <td>357</td>\n",
       "      <td>../data/docs/code-with-engineering/index.md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code-with-engineering</td>\n",
       "      <td>[page_content=\"Work Item ID\\n\\nFor more inform...</td>\n",
       "      <td>Work Item ID\\n\\nFor more information about how...</td>\n",
       "      <td>325</td>\n",
       "      <td>../data/docs/code-with-engineering/code-review...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     solutionops_section                                    document_object  \\\n",
       "0  code-with-engineering  [page_content='Structure of a Sprint\\n\\nThe pu...   \n",
       "1  code-with-engineering  [page_content='Who We Are\\n\\nOur team, ISE (In...   \n",
       "2  code-with-engineering  [page_content=\"Engineering Fundamentals Checkl...   \n",
       "3  code-with-engineering  [page_content='ISE Code-With Engineering Playb...   \n",
       "4  code-with-engineering  [page_content=\"Work Item ID\\n\\nFor more inform...   \n",
       "\n",
       "                                       document_text  document_length  \\\n",
       "0  Structure of a Sprint\\n\\nThe purpose of this d...              468   \n",
       "1  Who We Are\\n\\nOur team, ISE (Industry Solution...              263   \n",
       "2  Engineering Fundamentals Checklist\\n\\nThis che...              793   \n",
       "3  ISE Code-With Engineering Playbook\\n\\nAn engin...              357   \n",
       "4  Work Item ID\\n\\nFor more information about how...              325   \n",
       "\n",
       "                                       document_path  \n",
       "0  ../data/docs/code-with-engineering/SPRINT-STRU...  \n",
       "1          ../data/docs/code-with-engineering/ISE.md  \n",
       "2  ../data/docs/code-with-engineering/ENG-FUNDAME...  \n",
       "3        ../data/docs/code-with-engineering/index.md  \n",
       "4  ../data/docs/code-with-engineering/code-review...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_files = pd.DataFrame(markdown_documents)\n",
    "\n",
    "markdown_files.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs look at the distribution of tokens in the chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "markdown_files['tokens'] = markdown_files['document_text'].apply(\n",
    "    lambda x: encoding.encode(x))\n",
    "markdown_files['n_tokens'] = markdown_files['tokens'].apply(\n",
    "    len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.histogram(markdown_files, x='n_tokens',\n",
    "#                    title='Distribution of tokenization lengths', nbins=80, marginal='box')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./images/md_text_splitter_tokenization_lengths.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use chunk size = (quantile_1)/2 = 360/2 = 180 tokens. so that 75%+ of the documents will be represented by at least 2 chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks_tokens(documents: list) -> list:\n",
    "\n",
    "    markdown_splitter = MarkdownTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=180, chunk_overlap=30\n",
    "    )\n",
    "\n",
    "    chunk_id = 0\n",
    "\n",
    "    chunks = {\n",
    "        \"chunkId\": [],\n",
    "        \"chunkContent\": [],\n",
    "        \"source\": []\n",
    "    }\n",
    "\n",
    "    for document in documents:\n",
    "        current_chunks_text_list = markdown_splitter.split_text(\n",
    "            document[0].page_content)\n",
    "        for i, chunk in enumerate(current_chunks_text_list):\n",
    "            chunks['chunkId'].append(f\"chunk{chunk_id}_{i}\")\n",
    "            chunks['chunkContent'].append(chunk)\n",
    "            chunks['source'].append(document[0].metadata['source'])\n",
    "\n",
    "        chunk_id += 1\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_with_tokens = create_chunks_tokens(\n",
    "    markdown_files[\"document_object\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunkId</th>\n",
       "      <th>chunkContent</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chunk0_0</td>\n",
       "      <td>Structure of a Sprint\\n\\nThe purpose of this d...</td>\n",
       "      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chunk0_1</td>\n",
       "      <td>[ ] Build a Product Backlog\\n\\nSet up a projec...</td>\n",
       "      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chunk0_2</td>\n",
       "      <td>Design the first test cases\\n\\n[ ] Decide on b...</td>\n",
       "      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chunk0_3</td>\n",
       "      <td>Day 3\\n\\n[ ] Agree on code style and on how to...</td>\n",
       "      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chunk0_4</td>\n",
       "      <td>[ ] Agree on how to Design a feature and condu...</td>\n",
       "      <td>../data/docs/code-with-engineering/SPRINT-STRU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunkId                                       chunkContent  \\\n",
       "0  chunk0_0  Structure of a Sprint\\n\\nThe purpose of this d...   \n",
       "1  chunk0_1  [ ] Build a Product Backlog\\n\\nSet up a projec...   \n",
       "2  chunk0_2  Design the first test cases\\n\\n[ ] Decide on b...   \n",
       "3  chunk0_3  Day 3\\n\\n[ ] Agree on code style and on how to...   \n",
       "4  chunk0_4  [ ] Agree on how to Design a feature and condu...   \n",
       "\n",
       "                                              source  \n",
       "0  ../data/docs/code-with-engineering/SPRINT-STRU...  \n",
       "1  ../data/docs/code-with-engineering/SPRINT-STRU...  \n",
       "2  ../data/docs/code-with-engineering/SPRINT-STRU...  \n",
       "3  ../data/docs/code-with-engineering/SPRINT-STRU...  \n",
       "4  ../data/docs/code-with-engineering/SPRINT-STRU...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks_with_tokens = pd.DataFrame(chunks_with_tokens)\n",
    "df_chunks_with_tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs look at the distribution of lengths in the chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks_with_tokens['chunk_text_length'] = df_chunks_with_tokens['chunkContent'].apply(\n",
    "    lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.histogram(df_chunks_with_tokens, x='chunk_text_length',\n",
    "#                    title='Histogram of Chunk Text Length', nbins=80, marginal='box')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./images/md_text_splitter_histogram.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## 1. Fixed-sized chunking strategy\n",
    "\n",
    "This is one of the most basic form of splitting up text. It is the process of simply dividing the text into N-character sized chunks regardless of their content or form. This method isn't recommended for any applications - but it's a great starting point for us to understand the basics. -->\n",
    "<!--\n",
    "**[Why Chunking Size Matters](https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5)**\n",
    "\n",
    "When processing data, splitting the source documents into chunks requires care and expertise to ensure the resulting chunks are small enough to be effective during fact retrieval but not too small so that enough context is provided during summarization. The models used to generate embedding vectors have maximum limits on the text fragments provided as input. For example, the maximum length of input text for the Azure OpenAI embedding models is **8,191** tokens. Given that each token is around 4 characters of text for common OpenAI models, this maximum limit is equivalent to around 6000 words of text. If you're using these models to generate embeddings, it's critical that the input text stays under the limit. Partitioning your content into chunks ensures that your data can be processed by the Large Language Models (LLM) used for indexing and queries.\n",
    "\n",
    "**Relevance and Granularity**: A small chunk size, like 128, yields more granular chunks. This granularity, however, presents a risk: vital information might not be among the top retrieved chunks, especially if the similarity _top_k_ setting is as restrictive as 2. Conversely, a chunk size of 512 is likely to encompass all necessary information within the top chunks, ensuring that answers to queries are readily available. To navigate this, we employ the _Faithfulness and Relevancy_ metrics. These measure the absence of ‚Äòhallucinations‚Äô and the ‚Äòrelevancy‚Äô of responses based on the query and the retrieved contexts respectively.\n",
    "\n",
    "**Response Generation Time**: As the chunk_size increases, so does the volume of information directed into the LLM to generate an answer. While this can ensure a more comprehensive context, it might also slow down the system. Ensuring that the added depth doesn't compromise the system's responsiveness is crucial.\n",
    "\n",
    "In essence, determining the optimal chunk_size is about striking a balance: capturing all essential information without sacrificing speed. It's vital to undergo thorough testing with various sizes to find a configuration that suits the specific use case and dataset.\n",
    "\n",
    "- **Pros**: Easy & Simple\n",
    "- **Cons**: Very rigid and doesn't take into account the structure of your text\n",
    "\n",
    "Concept to know:\n",
    "\n",
    "- **Chunk Size** - The number of characters you would like in your chunks. 50, 100, 100,000, etc.\n",
    "- **Chunk Overlap** - The amount you would like your sequential chunks to overlap. This is to try to avoid cutting a single piece of context into multiple pieces. This will create duplicate data across chunks. -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "In the interest of time, we have already chunked the data from Solution Ops repo using Markdown Text Splitter using tiktoken encoder approach. The result can be found at [fixed-size-chunks-engineering-mlops-180-30.json.json](./output/pre-generated/chunking/fixed-size-chunks-engineering-mlops-180-30.json)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- In this workshop, to separate our experiments, we will take the _Full Reindex_ strategy by creating a new index -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. [Semantic Chunking](https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker)\n",
    "\n",
    "### Overview\n",
    "\n",
    "<!-- Azure: https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-retrieval-augumented-generation?view=doc-intel-4.0.0#semantic-chunking) -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous approach, we chose a constant value for chunk size, in a random way. We did not leverage the actual content of the document, the structure, etc. In this section, we will look at [Semantic Chunking](https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker) from LangChain. This approach splits the text based on semantic similarity.\n",
    "\n",
    "For insights on what it is doing, you can have a look at [Level 4. Semantic Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb). \n",
    "\n",
    "### Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This group is either determined by a specific time interval or a certain size limit. Stream ingestion deals with continuous, unbounded datasets. That said, most of the current stream ingestion approaches use mini-batches to ingest data as it reduces the number of I/O operations. ## Batch Ingestion\n",
      "\n",
      "Traditionally data ingestion has been done in batches due to the limitations of the legacy systems. It still remains a popular way to ingest data for the simplicity of its implementation. Almost every ETL tool supports batch ingestion. ### Batch Ingestion Architectural Patterns\n",
      "\n",
      "#### Pull\n",
      "\n",
      "Most batch ingestion data pipelines will connect to a source system and pull data from it at regular interval. There are two common patterns for a batch job to load data from a source system, full load and delta load. - _Full load_: The job will load all the records from the source table. - _Delta load_: The job will load only the new records added since the last execution of the job. For this approach to work, the source table needs to have a watermark column. ##### Azure Blob Storage Change Feed\n",
      "\n",
      "When the data source is Azure Blob Storage, the [Change Feed feature](https://learn.microsoft.com/azure/storage/blobs/storage-blob-change-feed) implements batch pull ingestion for either the full load or delta load scenarios. The Change Feed provides transactional logs of all the changes that occur to the blobs and the blob metadata inside of a storage account, in an efficient and scalable manner. {% if extra.ring == 'internal' %}\n",
      "The following repo provides a generic example for how to use the blob storage change feed in a batch ingestion process. [Azure Blob Storage Change Feed - Example](https://github.com/commercial-software-engineering/blob-storage-change-feed)\n",
      "{% endif %}\n",
      "\n",
      "#### Push\n",
      "\n",
      "Though pull-based model for data ingestion is the most fault tolerant model, its biggest drawback is lack of real-time information. The push-based model aims to solve the problem as the source system sends data to the target as soon as the data is generated.\n"
     ]
    }
   ],
   "source": [
    "%run -i ./pre-requisites.ipynb\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"embeddings-model\",\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    api_key=azure_openai_key\n",
    ")\n",
    "\n",
    "with open(\"../data/docs/code-with-mlops/capabilities/experimentation/index.md\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "\n",
    "text_splitter = SemanticChunker(embeddings)\n",
    "\n",
    "docs = text_splitter.create_documents([state_of_the_union])\n",
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "In the interest of time, we have already chunked the data from Solution Ops repo using Semantic Chunking approach. The result can be found at [semantic-chunks-engineering-mlops.json](./output/pre-generated/chunking/semantic-chunks-engineering-mlops.json)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Use the built-in skillset: [SplitSkill](https://learn.microsoft.com/en-us/azure/search/cognitive-search-skill-textsplit) -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Evaluation\n",
    "\n",
    "In this workshop, to separate our experiments, we will take the **Full Reindex** strategy and we will create a new index per chunking strategy.\n",
    "\n",
    "Therefore, for each chunking strategy we will:\n",
    "\n",
    "1. Create a new index. Note: make sure to give a relevant name.\n",
    "2. Embed the chunks that have been previously created. Note: In this experiment we are using AOI embedding model.\n",
    "3. Populate the index with chunks.\n",
    "\n",
    "```{note}\n",
    "In the interest of time, we have already embedded the chunks using OAI embedding model:\n",
    "- The pre-generated embeddings for Markdown Header Text Splitter can be found at [fixed-size-chunks-180-30-engineering-mlops-ada.json](./output/pre-generated/embeddings/fixed-size-chunks-180-30-engineering-mlops-ada.json)\n",
    "- The pre-generated embeddings for Markdown Text Splitter using tiktoken encode can be found at [md-header-text-splitter-engineering-mlops-embedded-ada](./output/pre-generated/embeddings/./md-header-text-splitter-engineering-mlops-embedded-ada.json)\n",
    "- The pre-generated embeddings for Semantic Chunking approach can be found at: [semantic-chunks-engineering-mlops-embedded-ada.json](./output/pre-generated/embeddings/./semantic-chunks-engineering-mlops-embedded-ada.json.json)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%run -i ./helpers/search.ipynb\n",
    "%run -i ./pre-requisites.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the path to each embedded chunks. Note the name of variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-generated embeddings for Markdown Header Text Splitter: ./output/pre-generated/embeddings/fixed-size-chunks-180-30-engineering-mlops-ada.json\n",
      "Pre-generated embeddings for Markdown Text Splitter using tiktoken encode: ./output/pre-generated/embeddings/md-header-text-splitter-engineering-mlops-embedded-ada.json\n",
      "Pre-generated embeddings for Semantic Chunks Splitter: ./output/pre-generated/embeddings/semantic-chunks-engineering-mlops-embedded-ada.json\n"
     ]
    }
   ],
   "source": [
    "%run -i ./pre-requisites.ipynb\n",
    "\n",
    "print(f\"Pre-generated embeddings for Markdown Header Text Splitter: {pregenerated_fixed_size_chunks_embeddings_ada}\")\n",
    "print(f\"Pre-generated embeddings for Markdown Text Splitter using tiktoken encode: {pregenerated_markdown_header_chunks_embeddings_ada}\")\n",
    "print(f\"Pre-generated embeddings for Semantic Chunks Splitter: {pregenerated_semantic_chunks_embeddings_ada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "You can reuse available functions from [./helpers/search.ipynb](./helpers/search.ipynb), such as: *create_index* and *upload_data*.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 3 search indexes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code for creating a new index and uploading the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 'fixed-size-180-30' created or updated\n",
      "Uploaded 3236 documents to Index: fixed-size-180-30\n"
     ]
    }
   ],
   "source": [
    "%run -i ./helpers/search.ipynb\n",
    "\n",
    "# 1. Create the new index\n",
    "index_name = \"fixed-size-180-30\"\n",
    "embedding_path = pregenerated_fixed_size_chunks_embeddings_ada\n",
    "create_index(index_name)\n",
    "\n",
    "# Uncomment the following code when running the cell:\n",
    "\n",
    "# # 3. Upload the embeddings to the new index\n",
    "upload_data(file_path=embedding_path, search_index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 'semantic-chunking' created or updated\n",
      "Uploaded 1216 documents to Index: semantic-chunking\n"
     ]
    }
   ],
   "source": [
    "%run -i ./helpers/search.ipynb\n",
    "\n",
    "# 1. Create the new index\n",
    "index_name = \"semantic-chunking\"\n",
    "embedding_path = pregenerated_semantic_chunks_embeddings_ada\n",
    "create_index(index_name)\n",
    "\n",
    "# 3. Upload the embeddings to the new index\n",
    "upload_data(file_path=embedding_path, search_index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./helpers/search.ipynb\n",
    "\n",
    "# 1. Create the new index\n",
    "index_name = \"markdown-header-chunking\"\n",
    "embedding_path = pregenerated_markdown_header_chunks_embeddings_ada\n",
    "create_index(index_name)\n",
    "\n",
    "# 3. Upload the embeddings to the new index\n",
    "upload_data(file_path=embedding_path, search_index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Evaluation Dataset\n",
    "\n",
    "Note: The evaluation dataset can be found at [solution-ops-200-qa.json](./output/qa/evaluation/qa_pairs_solutionops.json). The format is:\n",
    "\n",
    "```json\n",
    "\"user_prompt\": \"\", # The question\n",
    "\"output_prompt\": \"\", # The answer\n",
    "\"context\": \"\", # The relevant piece of information from a document\n",
    "\"chunk_id\": \"\", # The ID of the chunk\n",
    "\"source\": \"\" # The path to the document, i.e. \"..\\\\data\\\\docs\\\\code-with-dataops\\\\index.md\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us configure the path to evaluation dataset and reload environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./pre-requisites.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØEvaluation Metrics\n",
    "\n",
    "<!-- `Retrieval_evaluation` function goes through our evaluation dataset and verifies for each question if the retrieved documents include the expected document. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ./helpers/search.ipynb\n",
    "\n",
    "from statistics import mean, median\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the evaluation metrics:\n",
    "\n",
    "- Cosine similarity: will calculate the similarity between the first retrieved chunk and the expected chunk. We will look at the average and mean cosine similarity across our evaluation dataset.\n",
    "- Accuracy: we will calculate how many times the system returned the expected document, and by document we mean the actual path to the markdown file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(expected_document_vector, retrieved_document_vector):\n",
    "    cosine_sim = np.dot(expected_document_vector, retrieved_document_vector) / \\\n",
    "        (norm(expected_document_vector)*norm(retrieved_document_vector))\n",
    "    return float(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ntpath\n",
    "def calculate_metrics(evaluation_data_path, search_index_name, embedding_function=oai_query_embedding):\n",
    "    \"\"\" Evaluate the retrieval performance of the search index using the evaluation data set.\n",
    "    Args:\n",
    "    evaluation_data_path (str): The path to the evaluation data set.\n",
    "    embedding_function (function): The function to use for embedding the question.\n",
    "    search_index_name (str): The name of the search index to use for retrieval.\n",
    "\n",
    "    Returns:\n",
    "    list: The cosine similarities between the expected documents and the top retrieved documents.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(evaluation_data_path):\n",
    "        print(f\"The path to the evaluation data set {evaluation_data_path} does not exist. Please check the path and try again.\")\n",
    "        return\n",
    "    nr_correctly_retrieved_documents = 0\n",
    "    nr_qa = 0\n",
    "    cosine_similarities = []\n",
    "\n",
    "    with open(evaluation_data_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        evaluation_data = json.load(file)\n",
    "        for data in evaluation_data:\n",
    "            user_prompt = data[\"user_prompt\"]\n",
    "            expected_document = data[\"source\"]\n",
    "            expected_document_vector = embedding_function(data[\"context\"])\n",
    "\n",
    "            # 1. Search in the index\n",
    "            search_response = search_documents(\n",
    "                search_index_name=search_index_name,\n",
    "                input=user_prompt,\n",
    "                embedding_function=embedding_function,\n",
    "            )\n",
    "\n",
    "            retrieved_documents = [ntpath.normpath(response[\"source\"])\n",
    "                                   for response in search_response]\n",
    "            top_retrieved_document = search_response[0][\"chunkContentVector\"]\n",
    "\n",
    "\n",
    "            # 2. Calculate cosine similarity between the expected document and the top retrieved document\n",
    "            cosine_similarity = calculate_cosine_similarity(\n",
    "                expected_document_vector, top_retrieved_document)\n",
    "            cosine_similarities.append(cosine_similarity)\n",
    "\n",
    "            # 3. If the expected document is part of the retrieved documents,\n",
    "            # we will consider it correctly retrieved\n",
    "            if ntpath.normpath(expected_document) in retrieved_documents:\n",
    "                nr_correctly_retrieved_documents += 1\n",
    "            nr_qa += 1\n",
    "    accuracy = (nr_correctly_retrieved_documents / nr_qa)*100\n",
    "    print(f\"Accuracy: {accuracy}% of the documents were correctly retrieved from Index {index_name}.\")\n",
    "\n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üë©‚Äçüíª 1. Evaluate the Markdown Header Text Splitter - took 3 min\n",
    "\n",
    "<details markdown=\"1\">\n",
    "<summary> üîç Code. It may take up to 3 minutes: </summary>\n",
    "\n",
    "```python\n",
    "\n",
    "# TODO: Replace this with the name of the index you want to evaluate\n",
    "index_name = \"markdown-header-chunking\"\n",
    "\n",
    "cosine_similarities = calculate_metrics(\n",
    "    evaluation_data_path=path_to_evaluation_dataset,\n",
    "    search_index_name=index_name,\n",
    ")\n",
    "\n",
    "avg_score = mean(cosine_similarities)\n",
    "print(f\"Avg score:{avg_score}\")\n",
    "median_score = median(cosine_similarities)\n",
    "print(f\"Median score: {median_score}\")\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<!-- - Accuracy: 28.999999999999996% of the documents were correctly retrieved from Index markdwon-header-chunkig.\n",
    "\n",
    "- Avg cosine score:0.8077330619452607\n",
    "\n",
    "- Median cosine score: 0.8036465351518314 -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üë©‚Äçüíª 2. Evaluate the Markdown Text Splitter using tiktoken encode\n",
    "\n",
    "Note: It's equivalent to the first experiment.\n",
    "\n",
    "<details markdown=\"1\">\n",
    "<summary> üîç Code. It may take up to 3 minutes: </summary>\n",
    "\n",
    "```python\n",
    "\n",
    "# TODO: Replace this with the name of the index you want to evaluate\n",
    "index_name = \"fixed-size-180-30\"\n",
    "\n",
    "cosine_similarities = calculate_metrics(\n",
    "    evaluation_data_path=path_to_evaluation_dataset,\n",
    "    search_index_name=index_name,\n",
    ")\n",
    "\n",
    "avg_score = mean(cosine_similarities)\n",
    "print(f\"Avg score:{avg_score}\")\n",
    "median_score = median(cosine_similarities)\n",
    "print(f\"Median score: {median_score}\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üë©‚Äçüíª 3. Evaluate the semantic chunking strategy\n",
    "\n",
    "<!--\n",
    "- Accuracy: 70.33333333333334% of the documents were correctly retrieved from Index semantic-chunking.\n",
    "- Avg score:0.8640008644417442\n",
    "- Median score: 0.8739910472047012 -->\n",
    "\n",
    "<details markdown=\"1\">\n",
    "<summary> üîç Code. It may take up to 3 minutes: </summary>\n",
    "\n",
    "```python\n",
    "\n",
    "# TODO: Replace this with the name of the index you want to evaluate\n",
    "index_name = \"semantic-chunking\"\n",
    "\n",
    "cosine_similarities = calculate_metrics(\n",
    "    evaluation_data_path=path_to_evaluation_dataset,\n",
    "    search_index_name=index_name,\n",
    ")\n",
    "\n",
    "avg_score = mean(cosine_similarities)\n",
    "print(f\"Avg score:{avg_score}\")\n",
    "median_score = median(cosine_similarities)\n",
    "print(f\"Median score: {median_score}\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Conclusions\n",
    "\n",
    "Take few moments to analyse the results.\n",
    "\n",
    "<details markdown=\"1\">\n",
    "<summary> üîç Pre-calculated results: </summary>\n",
    "\n",
    "![results.png](./images/chunking-results.png)\n",
    "\n",
    "In terms of cosine similarity, all strategies got a good score. However, the \"Markdown Text splitter\" got the highest one.  In terms of accuracy, the markdown header text splitter is falling behind with only 63% accuracy. The Semantic chunker has a reasonable accuracy of 70%, but is far behind the \"Markdown text splitter\" one. That is a surprising result, as intuitively, we would have expected the semantic chunking strategy got the highest score. \n",
    "\n",
    "In reality, the results of \"Markdown Text splitter\" are better than it probably is in practice. Can you guess why? \n",
    "\n",
    "\n",
    "... \n",
    "In practice, the evaluation dataset is ideally created and curated by subject-matter human experts. In this workshop, we have created synthetic data ... using the markdown text splitter chunking strategy, so the results above are inherently biased. If one were to regenerate the data, one should consider to create question/answer pairs on a whole document rather than chunking every document.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with the final [end-to-end evaluation](./3.3.end_to_end_evaluation.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
