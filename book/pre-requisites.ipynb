{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## 1. Deploy required Azure resources:\n",
    "\n",
    "- Note: You need access to Azure OpenAI Service: [Request Access to Azure OpenAI Service](https://aka.ms/oai/access) & Visual Studio Code installed\n",
    "- Azure Search Service\n",
    "- Azure OpenAI Service in Sweden with text-embedding-ada-002, gpt3.5 model deployed (gpt4 for llm as a judge)\n",
    "<!-- (which can host one or more search indexes) with Semantic Ranker enabled. Note: it is not supported in sweden central https://azure.microsoft.com/en-us/explore/global-infrastructure/products-by-region/?products=search -->\n",
    "\n",
    "## 2. Set up the environment.\n",
    "\n",
    "You have three options.\n",
    "\n",
    "### a) Use Github Codespaces\n",
    "\n",
    "Use this option if you don't have either Python, Docker Desktop or Visual Studio Code installed on your machine.\n",
    "\n",
    "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](URL)\n",
    "\n",
    "### b) Use devcontainer\n",
    "\n",
    "Use this option if you have Visual Studio Code and Docker Desktop installed.\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Dev Containers: Rebuild and Reopen in Container**.\n",
    "\n",
    "### c) Set up a Python virtual environment in Visual Studio Code\n",
    "Note: this can take up a long time. To speed up the process, we have checked in the `.venv` - you can just reuse that for the workshop.\n",
    "\n",
    "Use this option if you have Visual Studio Code and Python installed.\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "1. Select _workshop\\book\\requirements.txt_ as dependencies to install.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments).\n",
    "If the dependencies were not installed, run\n",
    "\n",
    "```python\n",
    "%pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure .env file\n",
    "\n",
    "- First, copy `.env-sample` to `.env` and update the values accordingly.\n",
    "- Then, run the code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "service_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "search_index_key = os.environ[\"AZURE_SEARCH_ADMIN_KEY\"] if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else None\n",
    "azure_aoai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"] # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None\n",
    "azure_openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"] # used to be called azure_openai_embedding_deployment\n",
    "azure_openai_chat_deployment = os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"]\n",
    "\n",
    "credential = AzureKeyCredential(search_index_key) or DefaultAzureCredential()\n",
    "\n",
    "path_to_evaulation_dataset = \"./output/qa/evaluation/qa_pairs_solutionops.json\"\n",
    "\n",
    "pregenerated_data_path = \"./output/pre-generated\"\n",
    "\n",
    "pregenerated_fixed_size_chunks = f\"{pregenerated_data_path}/chunking/fixed-size-chunks-engineering-mlops-180-30.json\"\n",
    "pregenerated_md_header_chunks =  f\"{pregenerated_data_path}/chunking/md-header-text-splitter-engineering-mlops.json\"\n",
    "pregenerated_semantic_chunks = f\"{pregenerated_data_path}/chunking/semantic-chunks-engineering-mlops.json\"\n",
    "\n",
    "pregenerated_fixed_size_chunks_emebddings_ada = f\"{pregenerated_data_path}/embeddings/fixed-size-chunks-180-30-engineering-mlops-ada.json\"\n",
    "pregenerated_fixed_size_chunks_emebddings_os = f\"{pregenerated_data_path}/embeddings/fixed-size-chunks-180-30-engineering-mlops-e5-small-v2.json\"\n",
    "\n",
    "pregenerated_markdown_header_chunks_embeddings_ada = f\"{pregenerated_data_path}/embeddings/md-header-text-splitter-engineering-mlops-embedded-ada.json\"\n",
    "pregenerated_semantic_chunks_embeddings_ada = f\"{pregenerated_data_path}/embeddings/semantic-chunks-engineering-mlops-embedded-ada.json\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
